The push for digitization and automation of reports is becoming the standard and employers are now looking for candidates with exposure to business intelligence and statistical packages such as Python and Microsoft Power BI. As such, to improve my analytical skills via machine learning, I recently pursued a post graduate certificate in Data Analytics at Durham College.

This page will demonstrate my experience with data tools such as Microsoft Power BI, Tableau, MySQL, Python and more.

---

# Experience With Microsoft Power BI

I have utilized Microsoft Power BI to:
1. Transform data: eliminate unecessary data/ merge data sheets
2. Analyze data 
3. Draw insights to facilitate data based decision making
4. Create interactive visualizations and dashboards
5. Create reports and presentations


Below is a screenshot with interactive visualizations created in Power BI, assessing the order fulfillment for a company.  Filters were created to easily navigate by year, region, and business segment to give insight into the company's performance.


![image](https://user-images.githubusercontent.com/95316235/174681268-b9aa71b9-f159-4acc-b5a7-14004c5ce696.png)



Below is a video presentation created after generating insights using Power BI.  The subject centers around the Covid-19 pandemic and utilized data to determine if relaxing existing measures were appropriate. The assumption: "You have been hired as an advisor to the Prime Minister of Canada. Your task is to analyze the current COVID-19 situation, evaluate effectiveness of existing measures and recommend when Canada should call the end of pandemic."

<p align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/K_wMS8NMmgw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>


---

# Experience With Tableau

I have used Tableau to assess a number of datasets, create visualizations and assess performance by geographical location.  Below I will highlight a few projects which I have undertaken.

### Utlizing Data to Tell a Story

**Frankfurt Stock Exchange**

The raw dataset was provided. The ask: clean and arrange dataset, review and analyze data to derive a possible Challenge, Challenge Demonstration, Solution Introduction, Solution Description, Impact of Solution and Recommendation. In doing so, it is required to create your own logo and anything else needed to support the story.

<p align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/hxaJLa8Ld64" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>


**Vaccination Rates Globally**

Only raw dataset was provided.  The ask: use provided data to create a data narrative. Create personal brand and story and offer possible recommendation to a derived problem.

<p align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/2djFP3Gi7a4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>


### Dashboard Creation

Used dataset on job postings in Canada to create a dashboard based on insights generated.  The dataset was very large, as such, the dashboard highlighted the following:
1. The most popular job title
2. Province with the most job listings
3. Map depiction of hiring companies
4. Popular job titles in province generated from point 2
5. Jobs by province for title generated from point 1

**Insights**
1. Most popular job title was 'Data Analyst'
2. Province with the most job postings was Ontario
3. There were more hiring companies in Ontario - 1,321


**Takeaway**

Popular jobs are data centered, hence clients were encouraged to upskill in this area.

![Dashboard](https://user-images.githubusercontent.com/95316235/174660979-6b03dd46-a9b8-4e34-94a0-7af4d71cd83f.JPG)


---


# Experience With Python & R-Studio

I have experience with archiving python code into a Github repository, aggregating data (importing data from MySQL into python, then performing manipluations).  

I have used both Python and R-Studio to conduct exploratory data analysis, build models and answer research questions. This included training datasets, using machine learning techniques to eliminate outliers and address imbalance issues to generate more accurate predictive models.

**Some Engeering Techniques and Model Building Approach That Were Utilized**
1. Tukey
2. SMOTE
3. SelectFromModel
4. Learning curve generation
5. Logistic regression
6. Linear regression
7. Random forest and ensemble voting models
8. Creating dummy variables
9. Hypothesis testing



# Experience With MySQL

1. Database creation
2. Importing data into MySQL from Micrsoft Excel
3. Transforming data (Adding and removing columns/rows)
4. Adjusting data by periods and performing calculations to answer research questions

See example below.  The data was taken from the suggested list of datasets sourced from Kaggle.  The specific dataset used was ‘Video Game Sales with Ratings’.  This dataset tracks the sale of various video games from 1985 to present, highlighting among other things, sales in different regions and total global sales. In this screenshot I created a new column that labels records before 2010 as 'pre-2010' and after 2010 as 'post-2010'. 

![image](https://user-images.githubusercontent.com/95316235/174675816-190134c9-22fd-4c27-9559-c653c74466a9.png)


---

